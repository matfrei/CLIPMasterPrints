# Data
DATA:
  CAPTION_PATH: 'data/imagenet_classes.txt'

# Experiment parameters
RANDOM_SEED: 0
NUM_RUNS: 1
SAMPLE_CAPTIONS: [25]

# Experiment logging information
EXPERIMENT_LOG:
  BASEPATH: 'results-reproduced/CLIPMasterPrints'
  MODEL_NAME: 'CMA-ES+SDDecode'
  EXPERIMENT_NAME: 'mine-cmp-imagenet-classes-25-shift-0.25'

# Loss class to use
LOSS:
  CLASS: "CLIPLoss"

# parameters specific to autoencoder
AUTOENCODER:
  CLASS_NAME: 'StableDiffusionWrapper'
  CONFIG_PATH: '../external/stable-diffusion/configs/stable-diffusion/v1-inference.yaml'
  WEIGHT_PATH:  '../external/stable-diffusion/models/ldm/stable-diffusion-v1/model.ckpt'
  IMG_HEIGHT: 224
  IMG_WIDTH: 224
  LATENT_CHANNELS: 4
  DOWNSAMPLING_FACTOR: 8
  BATCH_SIZE: 40

# parameters specific to CLIP
CLIP:
  MODEL_STRINGS: ['ViT-L/14']
  SHIFT: 0.25

# optimizer to use
OPTIMIZER:
  METHOD: 'CMA-ES'
  ITER: 50000
  CHECK_POINT_AFTER_X_ITER: 10000
